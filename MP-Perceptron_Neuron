class Perceptron:
  def __init__(self):
    self.w=None
    self.b=None
    
  def model(self,x):
    return 1 if (np.dot(self.w,x)>=self.b) else 0
  
  def predict(self,X):
    Y=[]
    for x in X:
      result=self.model(x)
      Y.append(result)
    return np.array(Y)
  # Here epoch is also referred as hyper parameter 
  # Learning Rate : It determines how mush our parameters  will change
  #                 during training 
  def fit(self,X,Y,epochs=1,lr=1):
    
    self.w=np.ones(X.shape[1])
    self.b=0

    accuracy={}
    max_acc=0
    # Weight animation 
    wt_matrix=[]
    for i in range(epochs):
      for x,y in zip(X,Y):
        y_pred=self.model(x)
        if y_pred==1 and y==0:
          self.w=self.w-lr*x
          self.b=self.b-lr*1
        elif y_pred==0 and y==1:
          self.w=self.w+lr*x
          self.b=self.b+lr*1
        #adding rows in wt_matrix per epoch
     
        
      accuracy[i]=accuracy_score(self.predict(X),Y)
      if accuracy[i]>=max_acc:
        max_acc=accuracy[i]
        max_epoch=i+1
       # Check pointing : Used to store maximum accuracy
       #                  creating values of parameters
        chkptw=self.w
        chkptb=self.b
        wt_matrix.append(self.w)
    self.w=chkptw
    self.b=chkptb
               
    plt.plot(accuracy.values())
    plt.ylim(0,1)
    plt.show()
    print(max_epoch,max_acc)
    return np.array(wt_matrix)
      
